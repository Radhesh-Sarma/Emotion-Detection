{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GA_new_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOosST0VapPJoA2nrmR3v3A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Radhesh-Sarma/Emotion-Detection/blob/main/GA_new_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzHNio76WOKy",
        "outputId": "712769d3-bcb3-4974-b453-d5927b2eab99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy\n",
        "import sklearn.svm\n",
        "import numpy\n",
        "import matplotlib.pyplot\n",
        "import random\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import model_selection"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4B1QonEV-WM"
      },
      "source": [
        "def reduce_features(solution, features):\n",
        "    selected_elements_indices = numpy.where(solution == 1)[0]\n",
        "    reduced_features = features[:, selected_elements_indices]\n",
        "    return reduced_features\n",
        "\n",
        "\n",
        "def classification_accuracy(labels, predictions):\n",
        "    correct = numpy.where(labels == predictions)[0]\n",
        "    accuracy = correct.shape[0]/labels.shape[0]\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def cal_pop_fitness(pop, features, labels, train_indices, test_indices):\n",
        "    accuracies = numpy.zeros(pop.shape[0])\n",
        "    idx = 0\n",
        "\n",
        "    for curr_solution in pop:\n",
        "        reduced_features = reduce_features(curr_solution, features)\n",
        "        train_data = reduced_features[train_indices, :]\n",
        "        test_data = reduced_features[test_indices, :]\n",
        "\n",
        "        train_labels = labels[train_indices]\n",
        "        test_labels = labels[test_indices]\n",
        "\n",
        "        SV_classifier = sklearn.svm.SVC(gamma='scale')\n",
        "        SV_classifier.fit(X=train_data, y=train_labels)\n",
        "\n",
        "        predictions = SV_classifier.predict(test_data)\n",
        "        accuracies[idx] = classification_accuracy(test_labels, predictions)\n",
        "        idx = idx + 1\n",
        "    return accuracies\n",
        "\n",
        "def select_mating_pool(pop, fitness, num_parents):\n",
        "    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.\n",
        "    parents = numpy.empty((num_parents, pop.shape[1]))\n",
        "    for parent_num in range(num_parents):\n",
        "        max_fitness_idx = numpy.where(fitness == numpy.max(fitness))\n",
        "        max_fitness_idx = max_fitness_idx[0][0]\n",
        "        parents[parent_num, :] = pop[max_fitness_idx, :]\n",
        "        fitness[max_fitness_idx] = -99999999999\n",
        "    return parents\n",
        "\n",
        "\n",
        "def crossover(parents, offspring_size):\n",
        "    offspring = numpy.empty(offspring_size)\n",
        "    # The point at which crossover takes place between two parents. Usually, it is at the center.\n",
        "    crossover_point = numpy.uint8(offspring_size[1]/2)\n",
        "\n",
        "    for k in range(offspring_size[0]):\n",
        "        # Index of the first parent to mate.\n",
        "        parent1_idx = k%parents.shape[0]\n",
        "        # Index of the second parent to mate.\n",
        "        parent2_idx = (k+1)%parents.shape[0]\n",
        "        # The new offspring will have its first half of its genes taken from the first parent.\n",
        "        offspring[k, 0:crossover_point] = parents[parent1_idx, 0:crossover_point]\n",
        "        # The new offspring will have its second half of its genes taken from the second parent.\n",
        "        offspring[k, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
        "    return offspring\n",
        "\n",
        "\n",
        "def mutation(offspring_crossover, num_mutations=2):\n",
        "    mutation_idx = numpy.random.randint(low=0, high=offspring_crossover.shape[1], size=num_mutations)\n",
        "    # Mutation changes a single gene in each offspring randomly.\n",
        "    for idx in range(offspring_crossover.shape[0]):\n",
        "        # The random value to be added to the gene.\n",
        "        offspring_crossover[idx, mutation_idx] = 1 - offspring_crossover[idx, mutation_idx]\n",
        "    return offspring_crossover"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSX-enuOWJSs"
      },
      "source": [
        "def normalize(dataset):\n",
        "    dataNorm=((dataset-dataset.mean())/(dataset.std()))\n",
        "    dataNorm[\"Sad?\"]=dataset[\"Sad?\"]\n",
        "    return dataNorm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VSg78pmWooo",
        "outputId": "5d27af62-6a54-48d7-92d4-032252001b7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df = pd.read_csv('gdrive/My Drive/combined.csv')\n",
        "df=df.drop(['face'],1)\n",
        "df=df.drop(['Unnamed: 1'],1)\n",
        "print(df)\n",
        "  \n",
        "df = normalize(df)\n",
        "#df=df.drop('Unnamed: 1',axis=1,inplace=True)\n",
        "\n",
        "x = np.array(df.drop(['Sad?'],1))\n",
        "y = np.array(df['Sad?'])\n",
        "x_train,x_test,y_train,y_test = model_selection.train_test_split(x,y,test_size=0.2)\n",
        "\n",
        "data_inputs = x_train\n",
        "data_outputs = y_train"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Sad?  confidence  gaze_0_x  gaze_0_y  ...  AU25_c  AU26_c  AU28_c  AU45_c\n",
            "0       1       0.975  0.045100  0.261753  ...     0.0     0.0     1.0     0.0\n",
            "1       1       0.925  0.058224  0.235082  ...     0.0     0.0     0.0     0.0\n",
            "2       1       0.975  0.074234  0.026665  ...     0.0     0.0     0.0     0.0\n",
            "3       1       0.025  0.256086 -0.216004  ...     1.0     0.0     1.0     0.0\n",
            "4       1       0.975  0.193449  0.209023  ...     0.0     0.0     1.0     0.0\n",
            "..    ...         ...       ...       ...  ...     ...     ...     ...     ...\n",
            "121     0       0.875 -0.263258 -0.049040  ...     1.0     0.0     1.0     1.0\n",
            "122     0       0.775  0.509802 -0.322897  ...     0.0     0.0     1.0     0.0\n",
            "123     0       0.975  0.183691  0.158997  ...     1.0     1.0     0.0     0.0\n",
            "124     0       0.975 -0.010093  0.216590  ...     0.0     0.0     1.0     0.0\n",
            "125     0       0.975  0.145005  0.166456  ...     1.0     0.0     0.0     0.0\n",
            "\n",
            "[126 rows x 711 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqoVw1B9WJx1",
        "outputId": "f3daa7ee-807d-4d5f-e24b-98067405fbfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num_samples = data_inputs.shape[0]\n",
        "num_feature_elements = data_inputs.shape[1]\n",
        "\n",
        "train_indices = numpy.arange(1, num_samples, 4)\n",
        "test_indices = numpy.arange(0, num_samples, 4)\n",
        "print(\"Number of training samples: \", train_indices.shape[0])\n",
        "print(\"Number of test samples: \", test_indices.shape[0])\n",
        "\n",
        "\"\"\"\n",
        "Genetic algorithm parameters:\n",
        "    Population size\n",
        "    Mating pool size\n",
        "    Number of mutations\n",
        "\"\"\"\n",
        "sol_per_pop = 8 # Population size.\n",
        "num_parents_mating = 4 # Number of parents inside the mating pool.\n",
        "num_mutations = 3 # Number of elements to mutate.\n",
        "\n",
        "# Defining the population shape.\n",
        "pop_shape = (sol_per_pop, num_feature_elements)\n",
        "\n",
        "# Creating the initial population.\n",
        "new_population = numpy.random.randint(low=0, high=2, size=pop_shape)\n",
        "print(new_population.shape)\n",
        "\n",
        "best_outputs = []\n",
        "num_generations = 100\n",
        "for generation in range(num_generations):\n",
        "    print(\"Generation : \", generation)\n",
        "    # Measuring the fitness of each chromosome in the population.\n",
        "    fitness = cal_pop_fitness(new_population, data_inputs, data_outputs, train_indices, test_indices)\n",
        "\n",
        "    best_outputs.append(numpy.max(fitness))\n",
        "    # The best result in the current iteration.\n",
        "    print(\"Best result : \", best_outputs[-1])\n",
        "\n",
        "    # Selecting the best parents in the population for mating.\n",
        "    parents = select_mating_pool(new_population, fitness, num_parents_mating)\n",
        "\n",
        "    # Generating next generation using crossover.\n",
        "    offspring_crossover = crossover(parents, offspring_size=(pop_shape[0]-parents.shape[0], num_feature_elements))\n",
        "\n",
        "    # Adding some variations to the offspring using mutation.\n",
        "    offspring_mutation = mutation(offspring_crossover, num_mutations=num_mutations)\n",
        "\n",
        "    # Creating the new population based on the parents and offspring.\n",
        "    new_population[0:parents.shape[0], :] = parents\n",
        "    new_population[parents.shape[0]:, :] = offspring_mutation\n",
        "\n",
        "# Getting the best solution after iterating finishing all generations.\n",
        "# At first, the fitness is calculated for each solution in the final generation.\n",
        "fitness = cal_pop_fitness(new_population, data_inputs, data_outputs, train_indices, test_indices)\n",
        "# Then return the index of that solution corresponding to the best fitness.\n",
        "best_match_idx = numpy.where(fitness == numpy.max(fitness))[0]\n",
        "best_match_idx = best_match_idx[0]\n",
        "\n",
        "best_solution = new_population[best_match_idx, :]\n",
        "best_solution_indices = numpy.where(best_solution == 1)[0]\n",
        "best_solution_num_elements = best_solution_indices.shape[0]\n",
        "best_solution_fitness = fitness[best_match_idx]\n",
        "\n",
        "print(\"best_match_idx : \", best_match_idx)\n",
        "print(\"best_solution : \", best_solution)\n",
        "print(\"Selected indices : \", best_solution_indices)\n",
        "print(\"Number of selected elements : \", best_solution_num_elements)\n",
        "print(\"Best solution fitness : \", best_solution_fitness)\n",
        "\n",
        "matplotlib.pyplot.plot(best_outputs)\n",
        "matplotlib.pyplot.xlabel(\"Iteration\")\n",
        "matplotlib.pyplot.ylabel(\"Fitness\")\n",
        "matplotlib.pyplot.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples:  25\n",
            "Number of test samples:  25\n",
            "(8, 710)\n",
            "Generation :  0\n",
            "Best result :  0.52\n",
            "Generation :  1\n",
            "Best result :  0.52\n",
            "Generation :  2\n",
            "Best result :  0.52\n",
            "Generation :  3\n",
            "Best result :  0.52\n",
            "Generation :  4\n",
            "Best result :  0.52\n",
            "Generation :  5\n",
            "Best result :  0.52\n",
            "Generation :  6\n",
            "Best result :  0.52\n",
            "Generation :  7\n",
            "Best result :  0.52\n",
            "Generation :  8\n",
            "Best result :  0.52\n",
            "Generation :  9\n",
            "Best result :  0.52\n",
            "Generation :  10\n",
            "Best result :  0.52\n",
            "Generation :  11\n",
            "Best result :  0.52\n",
            "Generation :  12\n",
            "Best result :  0.52\n",
            "Generation :  13\n",
            "Best result :  0.52\n",
            "Generation :  14\n",
            "Best result :  0.52\n",
            "Generation :  15\n",
            "Best result :  0.52\n",
            "Generation :  16\n",
            "Best result :  0.52\n",
            "Generation :  17\n",
            "Best result :  0.52\n",
            "Generation :  18\n",
            "Best result :  0.52\n",
            "Generation :  19\n",
            "Best result :  0.52\n",
            "Generation :  20\n",
            "Best result :  0.52\n",
            "Generation :  21\n",
            "Best result :  0.52\n",
            "Generation :  22\n",
            "Best result :  0.52\n",
            "Generation :  23\n",
            "Best result :  0.52\n",
            "Generation :  24\n",
            "Best result :  0.52\n",
            "Generation :  25\n",
            "Best result :  0.52\n",
            "Generation :  26\n",
            "Best result :  0.52\n",
            "Generation :  27\n",
            "Best result :  0.52\n",
            "Generation :  28\n",
            "Best result :  0.52\n",
            "Generation :  29\n",
            "Best result :  0.52\n",
            "Generation :  30\n",
            "Best result :  0.52\n",
            "Generation :  31\n",
            "Best result :  0.52\n",
            "Generation :  32\n",
            "Best result :  0.52\n",
            "Generation :  33\n",
            "Best result :  0.52\n",
            "Generation :  34\n",
            "Best result :  0.52\n",
            "Generation :  35\n",
            "Best result :  0.52\n",
            "Generation :  36\n",
            "Best result :  0.52\n",
            "Generation :  37\n",
            "Best result :  0.52\n",
            "Generation :  38\n",
            "Best result :  0.52\n",
            "Generation :  39\n",
            "Best result :  0.52\n",
            "Generation :  40\n",
            "Best result :  0.52\n",
            "Generation :  41\n",
            "Best result :  0.52\n",
            "Generation :  42\n",
            "Best result :  0.52\n",
            "Generation :  43\n",
            "Best result :  0.52\n",
            "Generation :  44\n",
            "Best result :  0.52\n",
            "Generation :  45\n",
            "Best result :  0.52\n",
            "Generation :  46\n",
            "Best result :  0.52\n",
            "Generation :  47\n",
            "Best result :  0.52\n",
            "Generation :  48\n",
            "Best result :  0.52\n",
            "Generation :  49\n",
            "Best result :  0.52\n",
            "Generation :  50\n",
            "Best result :  0.52\n",
            "Generation :  51\n",
            "Best result :  0.52\n",
            "Generation :  52\n",
            "Best result :  0.52\n",
            "Generation :  53\n",
            "Best result :  0.52\n",
            "Generation :  54\n",
            "Best result :  0.52\n",
            "Generation :  55\n",
            "Best result :  0.52\n",
            "Generation :  56\n",
            "Best result :  0.52\n",
            "Generation :  57\n",
            "Best result :  0.52\n",
            "Generation :  58\n",
            "Best result :  0.52\n",
            "Generation :  59\n",
            "Best result :  0.52\n",
            "Generation :  60\n",
            "Best result :  0.52\n",
            "Generation :  61\n",
            "Best result :  0.52\n",
            "Generation :  62\n",
            "Best result :  0.52\n",
            "Generation :  63\n",
            "Best result :  0.52\n",
            "Generation :  64\n",
            "Best result :  0.52\n",
            "Generation :  65\n",
            "Best result :  0.52\n",
            "Generation :  66\n",
            "Best result :  0.52\n",
            "Generation :  67\n",
            "Best result :  0.52\n",
            "Generation :  68\n",
            "Best result :  0.52\n",
            "Generation :  69\n",
            "Best result :  0.52\n",
            "Generation :  70\n",
            "Best result :  0.52\n",
            "Generation :  71\n",
            "Best result :  0.52\n",
            "Generation :  72\n",
            "Best result :  0.52\n",
            "Generation :  73\n",
            "Best result :  0.52\n",
            "Generation :  74\n",
            "Best result :  0.52\n",
            "Generation :  75\n",
            "Best result :  0.52\n",
            "Generation :  76\n",
            "Best result :  0.52\n",
            "Generation :  77\n",
            "Best result :  0.52\n",
            "Generation :  78\n",
            "Best result :  0.52\n",
            "Generation :  79\n",
            "Best result :  0.52\n",
            "Generation :  80\n",
            "Best result :  0.52\n",
            "Generation :  81\n",
            "Best result :  0.52\n",
            "Generation :  82\n",
            "Best result :  0.52\n",
            "Generation :  83\n",
            "Best result :  0.52\n",
            "Generation :  84\n",
            "Best result :  0.52\n",
            "Generation :  85\n",
            "Best result :  0.52\n",
            "Generation :  86\n",
            "Best result :  0.52\n",
            "Generation :  87\n",
            "Best result :  0.52\n",
            "Generation :  88\n",
            "Best result :  0.52\n",
            "Generation :  89\n",
            "Best result :  0.52\n",
            "Generation :  90\n",
            "Best result :  0.52\n",
            "Generation :  91\n",
            "Best result :  0.52\n",
            "Generation :  92\n",
            "Best result :  0.52\n",
            "Generation :  93\n",
            "Best result :  0.52\n",
            "Generation :  94\n",
            "Best result :  0.52\n",
            "Generation :  95\n",
            "Best result :  0.52\n",
            "Generation :  96\n",
            "Best result :  0.52\n",
            "Generation :  97\n",
            "Best result :  0.52\n",
            "Generation :  98\n",
            "Best result :  0.52\n",
            "Generation :  99\n",
            "Best result :  0.52\n",
            "best_match_idx :  0\n",
            "best_solution :  [1 1 0 0 1 0 0 0 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 1\n",
            " 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 0 1 0 1 0 1 0\n",
            " 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1\n",
            " 1 0 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0\n",
            " 1 0 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 1\n",
            " 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 1 0 0 0 0 0 1 1 1 0\n",
            " 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 1 1 0 1 0\n",
            " 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 0 0 1 1 0 0 1 1 0 1 1 0 1 0 1\n",
            " 0 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 0 1 1 1 1\n",
            " 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1 1\n",
            " 1 1 1 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 1 0 1\n",
            " 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 1\n",
            " 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1\n",
            " 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1\n",
            " 1 1 1 0 1 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1\n",
            " 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 1\n",
            " 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0\n",
            " 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 1 0 0 0 0\n",
            " 0 0 0 1 1 1 0]\n",
            "Selected indices :  [  0   1   4   9  10  11  12  13  16  19  21  24  25  27  28  30  33  35\n",
            "  36  37  38  41  42  43  44  45  48  49  52  53  54  55  56  57  65  66\n",
            "  68  70  72  76  77  79  80  84  87  88  91  93  94 100 102 103 104 105\n",
            " 106 108 109 110 111 113 116 117 119 120 121 127 128 129 130 132 139 142\n",
            " 146 148 150 151 155 156 157 161 162 163 164 171 173 174 175 178 181 182\n",
            " 184 187 188 189 191 192 193 194 195 196 203 204 210 211 212 218 219 220\n",
            " 223 228 230 233 239 240 242 243 247 249 251 252 254 255 257 261 263 265\n",
            " 266 267 268 269 272 275 277 279 283 284 287 288 290 291 293 295 297 301\n",
            " 305 306 307 309 310 314 317 319 324 326 327 329 330 331 332 333 334 336\n",
            " 340 342 344 345 346 351 353 357 358 359 360 361 362 368 370 371 372 373\n",
            " 374 375 376 377 379 380 385 386 387 388 390 393 395 397 400 402 404 405\n",
            " 406 407 408 409 411 413 414 419 422 423 427 429 430 432 435 439 441 443\n",
            " 446 451 454 456 459 460 461 463 464 466 467 468 470 471 476 480 485 486\n",
            " 489 492 494 495 497 510 515 516 517 519 520 523 526 528 530 531 532 533\n",
            " 536 537 541 542 543 545 546 548 551 552 554 555 556 557 559 561 563 565\n",
            " 569 573 576 577 579 583 584 585 586 587 588 589 591 592 593 594 601 606\n",
            " 607 609 612 616 620 622 624 625 627 628 629 638 640 641 643 646 648 652\n",
            " 654 655 657 663 664 666 668 670 673 674 675 676 677 679 680 684 686 690\n",
            " 692 694 695 696 698 706 707 708]\n",
            "Number of selected elements :  332\n",
            "Best solution fitness :  0.52\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3Mem7vSXHEi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}